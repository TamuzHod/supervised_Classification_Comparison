{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import scipy\n",
    "from matplotlib.colors import ListedColormap\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)               # Set the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {0:'tic_tac',1:'adult',2:'cloud',3:'my_dota',4:'uci_data'}\n",
    "# choses via random dieroll\n",
    "random_seeds = [3,6,1,5,2,2,1,5,2,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data = pd.read_pickle(\"./data/cloud_data_sample.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kWh</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Surface Albedo</th>\n",
       "      <th>Precipitable Water</th>\n",
       "      <th>...</th>\n",
       "      <th>DNI</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Solar Zenith Angle</th>\n",
       "      <th>Clearsky GHI</th>\n",
       "      <th>Clearsky DNI</th>\n",
       "      <th>Clearsky DHI</th>\n",
       "      <th>lat</th>\n",
       "      <th>lang</th>\n",
       "      <th>binary_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PGE-CSI-07211_2011-01-14 09:30:00</th>\n",
       "      <td>0.11175</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>99.60</td>\n",
       "      <td>7</td>\n",
       "      <td>0.103</td>\n",
       "      <td>2.045</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8</td>\n",
       "      <td>71.12</td>\n",
       "      <td>298</td>\n",
       "      <td>724</td>\n",
       "      <td>63</td>\n",
       "      <td>37.870839</td>\n",
       "      <td>-122.272864</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGE-CSI-07352_2013-03-10 14:00:00</th>\n",
       "      <td>0.34250</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>45.28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.782</td>\n",
       "      <td>...</td>\n",
       "      <td>899</td>\n",
       "      <td>1.2</td>\n",
       "      <td>18</td>\n",
       "      <td>47.70</td>\n",
       "      <td>715</td>\n",
       "      <td>899</td>\n",
       "      <td>110</td>\n",
       "      <td>37.816833</td>\n",
       "      <td>-122.243348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGE-CSI-04978_2010-09-29 04:00:00</th>\n",
       "      <td>0.00250</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24.46</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.133</td>\n",
       "      <td>1.469</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>22</td>\n",
       "      <td>113.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.725584</td>\n",
       "      <td>-121.830222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGE-CSI-11837_2013-03-12 03:00:00</th>\n",
       "      <td>0.00075</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>94.11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.177</td>\n",
       "      <td>1.660</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9</td>\n",
       "      <td>128.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.677070</td>\n",
       "      <td>-121.739429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGE-CSI-07459_2014-11-01 03:00:00</th>\n",
       "      <td>0.00075</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>96.96</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116</td>\n",
       "      <td>1.884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12</td>\n",
       "      <td>132.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.271594</td>\n",
       "      <td>-122.005357</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       kWh  Year  Month  Day  Hour  Minute  \\\n",
       "data_id                                                                      \n",
       "PGE-CSI-07211_2011-01-14 09:30:00  0.11175  2011      1   14     9      30   \n",
       "PGE-CSI-07352_2013-03-10 14:00:00  0.34250  2013      3   10    14       0   \n",
       "PGE-CSI-04978_2010-09-29 04:00:00  0.00250  2010      9   29     4       0   \n",
       "PGE-CSI-11837_2013-03-12 03:00:00  0.00075  2013      3   12     3       0   \n",
       "PGE-CSI-07459_2014-11-01 03:00:00  0.00075  2014     11    1     3       0   \n",
       "\n",
       "                                   Relative Humidity  Dew Point  \\\n",
       "data_id                                                           \n",
       "PGE-CSI-07211_2011-01-14 09:30:00              99.60          7   \n",
       "PGE-CSI-07352_2013-03-10 14:00:00              45.28          5   \n",
       "PGE-CSI-04978_2010-09-29 04:00:00              24.46         -1   \n",
       "PGE-CSI-11837_2013-03-12 03:00:00              94.11          8   \n",
       "PGE-CSI-07459_2014-11-01 03:00:00              96.96         10   \n",
       "\n",
       "                                   Surface Albedo  Precipitable Water  ...  \\\n",
       "data_id                                                                ...   \n",
       "PGE-CSI-07211_2011-01-14 09:30:00           0.103               2.045  ...   \n",
       "PGE-CSI-07352_2013-03-10 14:00:00           0.111               0.782  ...   \n",
       "PGE-CSI-04978_2010-09-29 04:00:00           0.133               1.469  ...   \n",
       "PGE-CSI-11837_2013-03-12 03:00:00           0.177               1.660  ...   \n",
       "PGE-CSI-07459_2014-11-01 03:00:00           0.116               1.884  ...   \n",
       "\n",
       "                                   DNI  Wind Speed  Temperature  \\\n",
       "data_id                                                           \n",
       "PGE-CSI-07211_2011-01-14 09:30:00   16         1.7            8   \n",
       "PGE-CSI-07352_2013-03-10 14:00:00  899         1.2           18   \n",
       "PGE-CSI-04978_2010-09-29 04:00:00    0         1.3           22   \n",
       "PGE-CSI-11837_2013-03-12 03:00:00    0         0.7            9   \n",
       "PGE-CSI-07459_2014-11-01 03:00:00    0         1.1           12   \n",
       "\n",
       "                                   Solar Zenith Angle  Clearsky GHI  \\\n",
       "data_id                                                               \n",
       "PGE-CSI-07211_2011-01-14 09:30:00               71.12           298   \n",
       "PGE-CSI-07352_2013-03-10 14:00:00               47.70           715   \n",
       "PGE-CSI-04978_2010-09-29 04:00:00              113.88             0   \n",
       "PGE-CSI-11837_2013-03-12 03:00:00              128.61             0   \n",
       "PGE-CSI-07459_2014-11-01 03:00:00              132.53             0   \n",
       "\n",
       "                                   Clearsky DNI  Clearsky DHI        lat  \\\n",
       "data_id                                                                    \n",
       "PGE-CSI-07211_2011-01-14 09:30:00           724            63  37.870839   \n",
       "PGE-CSI-07352_2013-03-10 14:00:00           899           110  37.816833   \n",
       "PGE-CSI-04978_2010-09-29 04:00:00             0             0  39.725584   \n",
       "PGE-CSI-11837_2013-03-12 03:00:00             0             0  38.677070   \n",
       "PGE-CSI-07459_2014-11-01 03:00:00             0             0  37.271594   \n",
       "\n",
       "                                         lang  binary_class  \n",
       "data_id                                                      \n",
       "PGE-CSI-07211_2011-01-14 09:30:00 -122.272864            -1  \n",
       "PGE-CSI-07352_2013-03-10 14:00:00 -122.243348             1  \n",
       "PGE-CSI-04978_2010-09-29 04:00:00 -121.830222             1  \n",
       "PGE-CSI-11837_2013-03-12 03:00:00 -121.739429             1  \n",
       "PGE-CSI-07459_2014-11-01 03:00:00 -122.005357            -1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_data = cloud_data.sample(n=500, random_state=22)\n",
    "cloud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_won</th>\n",
       "      <th>hero_1</th>\n",
       "      <th>hero_2</th>\n",
       "      <th>hero_3</th>\n",
       "      <th>hero_4</th>\n",
       "      <th>hero_5</th>\n",
       "      <th>hero_6</th>\n",
       "      <th>hero_7</th>\n",
       "      <th>hero_8</th>\n",
       "      <th>hero_9</th>\n",
       "      <th>...</th>\n",
       "      <th>game_mode_3</th>\n",
       "      <th>game_mode_4</th>\n",
       "      <th>game_mode_5</th>\n",
       "      <th>game_mode_6</th>\n",
       "      <th>game_mode_7</th>\n",
       "      <th>game_mode_8</th>\n",
       "      <th>game_mode_9</th>\n",
       "      <th>game_type_1</th>\n",
       "      <th>game_type_2</th>\n",
       "      <th>game_type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12632</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47652</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70390</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_won  hero_1  hero_2  hero_3  hero_4  hero_5  hero_6  hero_7  \\\n",
       "12632        -1       0       0       0       0       0       0       0   \n",
       "37259         1       0       0       0       0       0       1       0   \n",
       "47652        -1       0       1       0       0       0       0       0   \n",
       "70390        -1       0       0       0       0       0       0       0   \n",
       "9144         -1       0       0       0       0       0       0       0   \n",
       "\n",
       "       hero_8  hero_9  ...  game_mode_3  game_mode_4  game_mode_5  \\\n",
       "12632       0       1  ...            0            0            0   \n",
       "37259       0       0  ...            0            0            0   \n",
       "47652       0       0  ...            0            0            0   \n",
       "70390       0       0  ...            0            0            0   \n",
       "9144       -1       0  ...            0            0            0   \n",
       "\n",
       "       game_mode_6  game_mode_7  game_mode_8  game_mode_9  game_type_1  \\\n",
       "12632            0            0            0            0            0   \n",
       "37259            0            0            0            0            0   \n",
       "47652            0            0            1            0            0   \n",
       "70390            0            0            1            0            0   \n",
       "9144             0            0            0            0            0   \n",
       "\n",
       "       game_type_2  game_type_3  \n",
       "12632            1            0  \n",
       "37259            0            1  \n",
       "47652            0            1  \n",
       "70390            1            0  \n",
       "9144             0            1  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_dota = pd.read_pickle(\"./data/uci_dota_sample.pkl\")  \n",
    "uci_dota = uci_dota.sample(n=500, random_state=22)\n",
    "uci_dota.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_won</th>\n",
       "      <th>hero_1</th>\n",
       "      <th>hero_2</th>\n",
       "      <th>hero_3</th>\n",
       "      <th>hero_4</th>\n",
       "      <th>hero_5</th>\n",
       "      <th>hero_6</th>\n",
       "      <th>hero_7</th>\n",
       "      <th>hero_8</th>\n",
       "      <th>hero_9</th>\n",
       "      <th>...</th>\n",
       "      <th>game_mode_2</th>\n",
       "      <th>game_mode_3</th>\n",
       "      <th>game_mode_4</th>\n",
       "      <th>game_mode_5</th>\n",
       "      <th>game_mode_18</th>\n",
       "      <th>game_mode_22</th>\n",
       "      <th>game_mode_23</th>\n",
       "      <th>game_type_0</th>\n",
       "      <th>game_type_1</th>\n",
       "      <th>game_type_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_won  hero_1  hero_2  hero_3  hero_4  hero_5  hero_6  hero_7  \\\n",
       "1176          1       0       0       0       0       0       0       0   \n",
       "12350        -1       0       0       0       0       0       0       0   \n",
       "9858          1       0       0       0       0       0       0       0   \n",
       "4387          1       0       0       0       0       0       0       0   \n",
       "12795         1       0       0       0       0       0       0       0   \n",
       "\n",
       "       hero_8  hero_9  ...  game_mode_2  game_mode_3  game_mode_4  \\\n",
       "1176        0       0  ...            0            0            0   \n",
       "12350       0       0  ...            0            0            0   \n",
       "9858        0       0  ...            0            0            0   \n",
       "4387        0       0  ...            0            0            0   \n",
       "12795       0       0  ...            0            0            0   \n",
       "\n",
       "       game_mode_5  game_mode_18  game_mode_22  game_mode_23  game_type_0  \\\n",
       "1176             0             0             1             0            0   \n",
       "12350            0             0             0             1            1   \n",
       "9858             0             0             1             0            0   \n",
       "4387             0             0             1             0            1   \n",
       "12795            0             0             0             1            1   \n",
       "\n",
       "       game_type_1  game_type_7  \n",
       "1176             0            1  \n",
       "12350            0            0  \n",
       "9858             0            1  \n",
       "4387             0            0  \n",
       "12795            0            0  \n",
       "\n",
       "[5 rows x 178 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dota = pd.read_pickle(\"./data/my_dota.pkl\")  \n",
    "my_dota = my_dota.sample(n=500, random_state=22)\n",
    "my_dota.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_ Portugal</th>\n",
       "      <th>native_country_ Puerto-Rico</th>\n",
       "      <th>native_country_ Scotland</th>\n",
       "      <th>native_country_ South</th>\n",
       "      <th>native_country_ Taiwan</th>\n",
       "      <th>native_country_ Thailand</th>\n",
       "      <th>native_country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_ United-States</th>\n",
       "      <th>native_country_ Vietnam</th>\n",
       "      <th>native_country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35057</th>\n",
       "      <td>18776</td>\n",
       "      <td>44</td>\n",
       "      <td>225263</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>7449</td>\n",
       "      <td>37</td>\n",
       "      <td>101020</td>\n",
       "      <td>13</td>\n",
       "      <td>4787</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22289</th>\n",
       "      <td>6008</td>\n",
       "      <td>51</td>\n",
       "      <td>114927</td>\n",
       "      <td>11</td>\n",
       "      <td>7298</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>11354</td>\n",
       "      <td>41</td>\n",
       "      <td>139160</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30394</th>\n",
       "      <td>14113</td>\n",
       "      <td>36</td>\n",
       "      <td>181589</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age  fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "35057       18776   44  225263             10             0          1408   \n",
       "7449         7449   37  101020             13          4787             0   \n",
       "22289        6008   51  114927             11          7298             0   \n",
       "11354       11354   41  139160             13             0             0   \n",
       "30394       14113   36  181589             13             0             0   \n",
       "\n",
       "       hours_per_week class  workclass_ ?  workclass_ Federal-gov  ...  \\\n",
       "35057              46     1             0                       0  ...   \n",
       "7449               55     1             0                       0  ...   \n",
       "22289              40     1             0                       0  ...   \n",
       "11354              40    -1             0                       0  ...   \n",
       "30394              32     1             0                       0  ...   \n",
       "\n",
       "       native_country_ Portugal  native_country_ Puerto-Rico  \\\n",
       "35057                         0                            0   \n",
       "7449                          0                            0   \n",
       "22289                         0                            0   \n",
       "11354                         0                            0   \n",
       "30394                         0                            0   \n",
       "\n",
       "       native_country_ Scotland  native_country_ South  \\\n",
       "35057                         0                      0   \n",
       "7449                          0                      0   \n",
       "22289                         0                      0   \n",
       "11354                         0                      0   \n",
       "30394                         0                      0   \n",
       "\n",
       "       native_country_ Taiwan  native_country_ Thailand  \\\n",
       "35057                       0                         0   \n",
       "7449                        0                         0   \n",
       "22289                       0                         0   \n",
       "11354                       0                         0   \n",
       "30394                       0                         0   \n",
       "\n",
       "       native_country_ Trinadad&Tobago  native_country_ United-States  \\\n",
       "35057                                0                              1   \n",
       "7449                                 0                              1   \n",
       "22289                                0                              1   \n",
       "11354                                0                              1   \n",
       "30394                                0                              0   \n",
       "\n",
       "       native_country_ Vietnam  native_country_ Yugoslavia  \n",
       "35057                        0                           0  \n",
       "7449                         0                           0  \n",
       "22289                        0                           0  \n",
       "11354                        0                           0  \n",
       "30394                        0                           0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_data = pd.read_csv(\"./data/adult_data.csv\")    \n",
    "adult_data['class'] = adult_data['class'].where(adult_data['class'] == adult_data['class'][0], 1)\n",
    "adult_data['class'] = adult_data['class'].where(adult_data['class'] == 1, -1)\n",
    "adult_data= adult_data.sample(n=500, random_state=22)\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_won</th>\n",
       "      <th>t_l_b</th>\n",
       "      <th>t_l_o</th>\n",
       "      <th>t_l_x</th>\n",
       "      <th>t_m_b</th>\n",
       "      <th>t_m_o</th>\n",
       "      <th>t_m_x</th>\n",
       "      <th>t_r_b</th>\n",
       "      <th>t_r_o</th>\n",
       "      <th>t_r_x</th>\n",
       "      <th>...</th>\n",
       "      <th>m_r_x</th>\n",
       "      <th>b_l_b</th>\n",
       "      <th>b_l_o</th>\n",
       "      <th>b_l_x</th>\n",
       "      <th>b_m_b</th>\n",
       "      <th>b_m_o</th>\n",
       "      <th>b_m_x</th>\n",
       "      <th>b_r_b</th>\n",
       "      <th>b_r_o</th>\n",
       "      <th>b_r_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  x_won  t_l_b  t_l_o  t_l_x  t_m_b  t_m_o  t_m_x  t_r_b  t_r_o  t_r_x  ...  \\\n",
       "0     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "1     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "2     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "3     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "4     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "\n",
       "   m_r_x  b_l_b  b_l_o  b_l_x  b_m_b  b_m_o  b_m_x  b_r_b  b_r_o  b_r_x  \n",
       "0      0      0      0      1      0      1      0      0      1      0  \n",
       "1      0      0      1      0      0      0      1      0      1      0  \n",
       "2      0      0      1      0      0      1      0      0      0      1  \n",
       "3      0      0      1      0      1      0      0      1      0      0  \n",
       "4      0      1      0      0      0      1      0      1      0      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_data = pd.read_pickle(\"./data/tic_tac_data.pkl\")  \n",
    "tic_tac_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X.append(cloud_data.drop(columns='binary_class'))\n",
    "X.append(tic_tac_data.drop(columns='x_won'))\n",
    "X.append(adult_data.drop(columns='class'))\n",
    "X.append(uci_dota.drop(columns='team_won'))\n",
    "X.append(my_dota.drop(columns='team_won'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "Y.append(cloud_data['binary_class'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(tic_tac_data['x_won'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(adult_data['class'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(uci_dota['team_won'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(my_dota['team_won'].values.reshape(-1,1).astype(np.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_train_test(prop_test):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for i in datasets.keys():\n",
    "       # print()\n",
    "        X_and_Y = np.hstack((X[i], Y[i]))     # Stack them together for shuffling.\n",
    "        np.random.shuffle(X_and_Y)      # Shuffle the data points in X_and_Y array\n",
    "\n",
    "        #print(datasets[i])\n",
    "       # print('X', X[i].shape)\n",
    "       # print('Y', Y[i].shape)\n",
    "        \n",
    "        X_shuffled = X_and_Y[:,:-1]\n",
    "        Y_shuffled = X_and_Y[:,-1]\n",
    "        \n",
    "        pivot = int(X[i].shape[0]*(1-prop_test))\n",
    "        X_train.append(X_shuffled[:pivot]) \n",
    "        Y_train.append(Y_shuffled[:pivot])             \n",
    "        X_test.append(X_shuffled[pivot:]) \n",
    "        Y_test.append(Y_shuffled[pivot:])\n",
    "        \n",
    "       # print('X_train', X_train[i].shape)\n",
    "       # print('Y_train', Y_train[i].shape)\n",
    "        \n",
    "       # print('X_test', X_test[i].shape)\n",
    "       # print('Y_test', Y_test[i].shape)\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns       \n",
    "import numbers\n",
    "import copy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "cv_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explained_variance': make_scorer(explained_variance_score),\n",
       " 'r2': make_scorer(r2_score),\n",
       " 'max_error': make_scorer(max_error, greater_is_better=False),\n",
       " 'neg_median_absolute_error': make_scorer(median_absolute_error, greater_is_better=False),\n",
       " 'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       " 'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       " 'neg_mean_squared_log_error': make_scorer(mean_squared_log_error, greater_is_better=False),\n",
       " 'neg_root_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False, squared=False),\n",
       " 'neg_mean_poisson_deviance': make_scorer(mean_poisson_deviance, greater_is_better=False),\n",
       " 'neg_mean_gamma_deviance': make_scorer(mean_gamma_deviance, greater_is_better=False),\n",
       " 'accuracy': make_scorer(accuracy_score),\n",
       " 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True),\n",
       " 'roc_auc_ovr': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovr),\n",
       " 'roc_auc_ovo': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovo),\n",
       " 'roc_auc_ovr_weighted': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovr, average=weighted),\n",
       " 'roc_auc_ovo_weighted': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovo, average=weighted),\n",
       " 'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
       " 'average_precision': make_scorer(average_precision_score, needs_threshold=True),\n",
       " 'neg_log_loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True),\n",
       " 'neg_brier_score': make_scorer(brier_score_loss, greater_is_better=False, needs_proba=True),\n",
       " 'adjusted_rand_score': make_scorer(adjusted_rand_score),\n",
       " 'homogeneity_score': make_scorer(homogeneity_score),\n",
       " 'completeness_score': make_scorer(completeness_score),\n",
       " 'v_measure_score': make_scorer(v_measure_score),\n",
       " 'mutual_info_score': make_scorer(mutual_info_score),\n",
       " 'adjusted_mutual_info_score': make_scorer(adjusted_mutual_info_score),\n",
       " 'normalized_mutual_info_score': make_scorer(normalized_mutual_info_score),\n",
       " 'fowlkes_mallows_score': make_scorer(fowlkes_mallows_score),\n",
       " 'precision': make_scorer(precision_score, average=binary),\n",
       " 'precision_macro': make_scorer(precision_score, pos_label=None, average=macro),\n",
       " 'precision_micro': make_scorer(precision_score, pos_label=None, average=micro),\n",
       " 'precision_samples': make_scorer(precision_score, pos_label=None, average=samples),\n",
       " 'precision_weighted': make_scorer(precision_score, pos_label=None, average=weighted),\n",
       " 'recall': make_scorer(recall_score, average=binary),\n",
       " 'recall_macro': make_scorer(recall_score, pos_label=None, average=macro),\n",
       " 'recall_micro': make_scorer(recall_score, pos_label=None, average=micro),\n",
       " 'recall_samples': make_scorer(recall_score, pos_label=None, average=samples),\n",
       " 'recall_weighted': make_scorer(recall_score, pos_label=None, average=weighted),\n",
       " 'f1': make_scorer(f1_score, average=binary),\n",
       " 'f1_macro': make_scorer(f1_score, pos_label=None, average=macro),\n",
       " 'f1_micro': make_scorer(f1_score, pos_label=None, average=micro),\n",
       " 'f1_samples': make_scorer(f1_score, pos_label=None, average=samples),\n",
       " 'f1_weighted': make_scorer(f1_score, pos_label=None, average=weighted),\n",
       " 'jaccard': make_scorer(jaccard_score, average=binary),\n",
       " 'jaccard_macro': make_scorer(jaccard_score, pos_label=None, average=macro),\n",
       " 'jaccard_micro': make_scorer(jaccard_score, pos_label=None, average=micro),\n",
       " 'jaccard_samples': make_scorer(jaccard_score, pos_label=None, average=samples),\n",
       " 'jaccard_weighted': make_scorer(jaccard_score, pos_label=None, average=weighted)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_validation_curve(grid, param_to_vary,\n",
    "                                      title='Validation Curve', ylim=None,\n",
    "                                      xlim=None, log=None):\n",
    "    \"\"\"Plots train and cross-validation scores from a GridSearchCV instance's\n",
    "    best params while varying one of those params.\"\"\"\n",
    "\n",
    "    df_cv_results = pd.DataFrame(grid.cv_results_)\n",
    "    train_scores_mean = df_cv_results['mean_train_score']\n",
    "    valid_scores_mean = df_cv_results['mean_test_score']\n",
    "    train_scores_std = df_cv_results['std_train_score']\n",
    "    valid_scores_std = df_cv_results['std_test_score']\n",
    "\n",
    "    param_cols = [c for c in df_cv_results.columns if c[:6] == 'param_']\n",
    "    param_ranges = [grid.param_grid[p[6:]] for p in param_cols]\n",
    "    param_ranges_lengths = [len(pr) for pr in param_ranges]\n",
    "\n",
    "    train_scores_mean = np.array(train_scores_mean).reshape(*param_ranges_lengths)\n",
    "    valid_scores_mean = np.array(valid_scores_mean).reshape(*param_ranges_lengths)\n",
    "    train_scores_std = np.array(train_scores_std).reshape(*param_ranges_lengths)\n",
    "    valid_scores_std = np.array(valid_scores_std).reshape(*param_ranges_lengths)\n",
    "\n",
    "    param_to_vary_idx = param_cols.index('param_{}'.format(param_to_vary))\n",
    "\n",
    "    slices = []\n",
    "    for idx, param in enumerate(grid.best_params_):\n",
    "        if (idx == param_to_vary_idx):\n",
    "            slices.append(slice(None))\n",
    "            continue\n",
    "        best_param_val = grid.best_params_[param]\n",
    "        idx_of_best_param = 0\n",
    "        if isinstance(param_ranges[idx], np.ndarray):\n",
    "            idx_of_best_param = param_ranges[idx].tolist().index(best_param_val)\n",
    "        else:\n",
    "            idx_of_best_param = param_ranges[idx].index(best_param_val)\n",
    "        slices.append(idx_of_best_param)\n",
    "\n",
    "    train_scores_mean = train_scores_mean[tuple(slices)]\n",
    "    valid_scores_mean = valid_scores_mean[tuple(slices)]\n",
    "    train_scores_std = train_scores_std[tuple(slices)]\n",
    "    valid_scores_std = valid_scores_std[tuple(slices)]\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_to_vary)\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    if (ylim is None):\n",
    "        plt.ylim(0.0, 1.1)\n",
    "    else:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    if (not (xlim is None)):\n",
    "        plt.xlim(*xlim)\n",
    "\n",
    "    lw = 2\n",
    "\n",
    "    plot_fn = plt.plot\n",
    "    if log:\n",
    "        plot_fn = plt.semilogx\n",
    "\n",
    "    param_range = param_ranges[param_to_vary_idx]\n",
    "    if (not isinstance(param_range[0], numbers.Number)):\n",
    "        param_range = [str(x) for x in param_range]\n",
    "    plot_fn(param_range, train_scores_mean, label='Training score', color='r',\n",
    "            lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='r', lw=lw)\n",
    "    plot_fn(param_range, valid_scores_mean, label='Cross-validation score',\n",
    "            color='b', lw=lw)\n",
    "    plt.fill_between(param_range, valid_scores_mean - valid_scores_std,\n",
    "                     valid_scores_mean + valid_scores_std, alpha=0.1,\n",
    "                     color='b', lw=lw)\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error(Y_pred, Y):\n",
    "    return np.array(y_predicted !=  Y_test[0]).astype(np.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN model\n",
    "pipe_knn = Pipeline([\n",
    "    ('sc', StandardScaler()),     \n",
    "    ('knn', KNeighborsClassifier()) \n",
    "])\n",
    "k_max = 10\n",
    "\n",
    "def get_knn_parm(n):\n",
    "    step = math.log((n / cv_num) * (cv_num-1) ,k_max)\n",
    "    return {'knn__n_neighbors': np.power(np.arange(1,k_max), step).astype(int), 'knn__p' : [1, 2,3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "pipe_svm = Pipeline([\n",
    "    ('sc', StandardScaler()),     \n",
    "    ('svm', SVC()) \n",
    "])\n",
    "\n",
    "def get_svm_parm(n):\n",
    "    return {'svm__C': [10**c for c in np.arange(-7,3, dtype=float)], 'svm__kernel' : ['linear','rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model\n",
    "pipe_rf = Pipeline([\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "# used https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 \n",
    "# to get reasonble RF hyperparmeters then changed it to match http://lowrank.net/nikos/pubs/empirical.pdf\n",
    "def get_rv_parm(n):\n",
    "    s = int(n**0.5)\n",
    "    n_estimators = [2**c for c in np.arange(7,13, dtype=int)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    min_samples_split = [int(2**c * s) for c in np.arange(-1,4, dtype=float)]\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'rf__n_estimators': n_estimators,\n",
    "                   'rf__max_features': max_features,\n",
    "                   'rf__min_samples_split': min_samples_split,\n",
    "                   'rf__bootstrap': bootstrap}\n",
    "    return random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'KNN' : \n",
    "                    {'pipe' : pipe_knn, 'params' : get_knn_parm, 'grid_list':[],'test_auc':[],'train_auc':[],'val_auc':[]},\n",
    "                'SVM' : \n",
    "                   {'pipe' : pipe_svm, 'params' : get_svm_parm, 'grid_list':[],'test_auc':[],'train_auc':[],'val_auc':[]},\n",
    "               'RF' :\n",
    "                    {'pipe' : pipe_rf, 'params' : get_rv_parm, 'grid_list':[],'test_auc':[],'train_auc':[],'val_auc':[]}\n",
    "              }\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scorer = make_scorer(roc_auc_score, needs_threshold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y, model):\n",
    "    clf = RandomizedSearchCV(estimator=model['pipe'],n_iter = 15,           \n",
    "                  param_distributions=model['params'](x.shape[0]), \n",
    "                  cv=cv_num,\n",
    "                  return_train_score=True,n_jobs=5, pre_dispatch = '2*n_jobs',  refit=True,\n",
    "                             scoring = scorer)\n",
    "\n",
    "    return clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test,y_test, model):\n",
    "    return scorer(model,x_test,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = copy.deepcopy(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "partions = [0.2,0.5,0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_results_dic(partions, datasets, classifiers):\n",
    "    results_dic = {}\n",
    "    for i, part in enumerate(partions, start=0):\n",
    "        results_dic[i] = {'partion' : part, 'datasets':{}}\n",
    "        for dataset in datasets.items():\n",
    "            results_dic[i]['datasets'][dataset[1]] = {'index' : dataset[0], 'classifiers':copy.deepcopy(classifiers)}\n",
    "    return results_dic\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_avrg_auc_over_n_trials(n, results_dic):\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        print('\\ttrial', i)\n",
    "        X_train, Y_train, X_test, Y_test = get_random_train_test(results_dic['partion'])\n",
    "        for dataset in results_dic['datasets']:\n",
    "            print('\\t\\tdataset', dataset)\n",
    "            dataset = results_dic['datasets'][dataset]\n",
    "            for classifier in dataset['classifiers']:\n",
    "               # print('\\t\\t\\ttunning ', classifier)\n",
    "                classifier = dataset['classifiers'][classifier]\n",
    "                grid = train(X_train[dataset['index']],Y_train[dataset['index']], classifier)\n",
    "                classifier['test_auc'].append(test(X_test[dataset['index']], Y_test[dataset['index']],grid))\n",
    "                classifier['train_auc'].append(grid.cv_results_['mean_train_score'][grid.best_index_])\n",
    "                classifier['val_auc'].append(grid.cv_results_['mean_test_score'][grid.best_index_])\n",
    "\n",
    "                classifier['grid_list'].append(grid)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_core_loop():\n",
    "    results_dic = new_results_dic(partions, datasets, classifiers)\n",
    "    for part in results_dic.values():\n",
    "        print('partion', part['partion'])\n",
    "        update_avrg_auc_over_n_trials(3, part)\n",
    "    return results_dic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partion 0.2\n",
      "\ttrial 0\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "\ttrial 1\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "\ttrial 2\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "partion 0.5\n",
      "\ttrial 0\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "\ttrial 1\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "\ttrial 2\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "partion 0.8\n",
      "\ttrial 0\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "\ttrial 1\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n",
      "\t\tdataset cloud\n",
      "\t\tdataset my_dota\n",
      "\t\tdataset uci_data\n",
      "\ttrial 2\n",
      "\t\tdataset tic_tac\n",
      "\t\tdataset adult\n"
     ]
    }
   ],
   "source": [
    "results_dic = run_core_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_str(part):\n",
    "    return ' ' + str(int(round((100*(1-part['partion']))))) + '/' +str(int(round((100*part['partion'])))) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ classifier + get_part_str(part) + auc + ' ' + end for classifier in classifiers.keys() \n",
    "           for part in results_dic.values() for auc in ['test','train','val'] for end in ['auc', 'std', 'text']]\n",
    "avreges_names = ([classifier+ ' mean ' + auc for classifier in classifiers.keys() for auc in ['auc']])\n",
    "columns += avreges_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "from statistics import stdev as std \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery = pd.DataFrame(columns=columns, index=results_dic[0]['datasets'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for part in results_dic.values():\n",
    "    for dataset in part['datasets']:\n",
    "        row = final_summery.loc[dataset]\n",
    "        dataset = part['datasets'][dataset]\n",
    "        for classifier in dataset['classifiers']:\n",
    "            columns_head = classifier + get_part_str(part)\n",
    "            classifier = dataset['classifiers'][classifier]\n",
    "            for auc in ['test','train','val']:\n",
    "                values = classifier[auc+'_auc'] \n",
    "                \n",
    "                row[columns_head + auc + ' auc'] = round(mean(values)* 100, ndigits=1)\n",
    "                row[columns_head + auc + ' std'] = round(std(values)* 100, ndigits=1)\n",
    "                row[columns_head + auc + ' text'] = str( round(mean(values)* 100, ndigits=1)) + ' +- ' + str(round(std(values)* 100, ndigits=1)) + '%'\n",
    "\n",
    "            \n",
    "        for name in avreges_names:\n",
    "            values = row.filter(regex='^'+name.split()[0]+'.*.*test.*' + name.split()[2])\n",
    "            row[name] = round(values.mean(), ndigits=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery[[c for c in columns if 'text' not in c]] = final_summery[[c for c in columns if 'text' not in c]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery[[c for c in columns if 'test text' in c or 'mean' in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery['80/20 best'] = [name.split()[0] for name in final_summery[[c for c in columns if '80/20 test auc' in c]].idxmax(axis=1)]\n",
    "final_summery['50/50 best'] = [name.split()[0] for name in final_summery[[c for c in columns if '50/50 test auc' in c]].idxmax(axis=1)]\n",
    "final_summery['20/80 best'] = [name.split()[0] for name in final_summery[[c for c in columns if '20/80 test auc' in c]].idxmax(axis=1)]\n",
    "final_summery['mean  best'] = [name.split()[0] for name in final_summery[[c for c in columns if 'mean auc' in c]].idxmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_grid_search_validation_curve(grid, 'knn__p', log=False, ylim=(.4, 1.02))\n",
    "#plot_grid_search_validation_curve(grid, 'knn__n_neighbors', log=True, ylim=(.4, 1.02))\n",
    "#parm = classifiers['KNN']['params'](X_train[0].shape[0])\n",
    "#scores = grid.cv_results_['mean_test_score'].reshape(len(parm['knn__n_neighbors']),len(parm['knn__p']))\n",
    "#ax = sns.heatmap(scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "79.3+81.5+78.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "76.7+80.4+75.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery.loc['cloud'][[c for c in columns if 'test auc' in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery.filter(regex='.*best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes =  plt.subplots(nrows=2, ncols=2,figsize=(15,10))\n",
    "final_summery[[c for c in columns if 'mean auc' in c]].plot(subplots=False,ax=axes[0,0])\n",
    "final_summery[[c for c in columns if '80/20 test auc' in c]].plot(subplots=False,ax=axes[0,1])\n",
    "final_summery[[c for c in columns if '50/50 test auc' in c]].plot(subplots=False,ax=axes[1,0])\n",
    "final_summery[[c for c in columns if '20/80 test auc' in c]].plot(subplots=False,ax=axes[1,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summery.filter(regex='.*text').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.externals import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(knn, 'filename.pkl') \n",
    "  \n",
    "# Load the model from the file \n",
    "knn_from_joblib = joblib.load('filename.pkl') \n",
    "\n",
    "s = pickle.dumps(clf)\n",
    "\n",
    "clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
