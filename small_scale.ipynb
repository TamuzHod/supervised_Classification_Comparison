{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import scipy\n",
    "from matplotlib.colors import ListedColormap\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)               # Set the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {0:'tic_tac',1:'adult',2:'cloud',3:'my_dota',4:'uci_data'}\n",
    "# choses via random dieroll\n",
    "random_seeds = [3,6,1,5,2,2,1,5,2,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data = pd.read_pickle(\"./data/cloud_data_sample.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data = cloud_data.sample(n=500, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_dota = pd.read_pickle(\"./data/uci_dota_sample.pkl\")  \n",
    "uci_dota = uci_dota.sample(n=500, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dota = pd.read_pickle(\"./data/my_dota.pkl\")  \n",
    "my_dota = my_dota.sample(n=500, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data = pd.read_csv(\"./data/adult_data.csv\")    \n",
    "adult_data['class'] = adult_data['class'].where(adult_data['class'] == adult_data['class'][0], 1)\n",
    "adult_data['class'] = adult_data['class'].where(adult_data['class'] == 1, -1)\n",
    "adult_data= adult_data.sample(n=500, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_won</th>\n",
       "      <th>t_l_b</th>\n",
       "      <th>t_l_o</th>\n",
       "      <th>t_l_x</th>\n",
       "      <th>t_m_b</th>\n",
       "      <th>t_m_o</th>\n",
       "      <th>t_m_x</th>\n",
       "      <th>t_r_b</th>\n",
       "      <th>t_r_o</th>\n",
       "      <th>t_r_x</th>\n",
       "      <th>...</th>\n",
       "      <th>m_r_x</th>\n",
       "      <th>b_l_b</th>\n",
       "      <th>b_l_o</th>\n",
       "      <th>b_l_x</th>\n",
       "      <th>b_m_b</th>\n",
       "      <th>b_m_o</th>\n",
       "      <th>b_m_x</th>\n",
       "      <th>b_r_b</th>\n",
       "      <th>b_r_o</th>\n",
       "      <th>b_r_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  x_won  t_l_b  t_l_o  t_l_x  t_m_b  t_m_o  t_m_x  t_r_b  t_r_o  t_r_x  ...  \\\n",
       "0     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "1     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "2     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "3     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "4     1      0      0      1      0      0      1      0      0      1  ...   \n",
       "\n",
       "   m_r_x  b_l_b  b_l_o  b_l_x  b_m_b  b_m_o  b_m_x  b_r_b  b_r_o  b_r_x  \n",
       "0      0      0      0      1      0      1      0      0      1      0  \n",
       "1      0      0      1      0      0      0      1      0      1      0  \n",
       "2      0      0      1      0      0      1      0      0      0      1  \n",
       "3      0      0      1      0      1      0      0      1      0      0  \n",
       "4      0      1      0      0      0      1      0      1      0      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_data = pd.read_pickle(\"./data/tic_tac_data.pkl\")  \n",
    "tic_tac_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X.append(tic_tac_data.drop(columns='x_won'))\n",
    "X.append(adult_data.drop(columns='class'))\n",
    "X.append(cloud_data.drop(columns='binary_class'))\n",
    "X.append(my_dota.drop(columns='team_won'))\n",
    "X.append(uci_dota.drop(columns='team_won'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "Y.append(tic_tac_data['x_won'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(adult_data['class'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(cloud_data['binary_class'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(my_dota['team_won'].values.reshape(-1,1).astype(np.float))\n",
    "Y.append(uci_dota['team_won'].values.reshape(-1,1).astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_train_test(prop_test):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for i in datasets.keys():\n",
    "       # print()\n",
    "        X_and_Y = np.hstack((X[i], Y[i]))     # Stack them together for shuffling.\n",
    "        np.random.shuffle(X_and_Y)      # Shuffle the data points in X_and_Y array\n",
    "\n",
    "        #print(datasets[i])\n",
    "       # print('X', X[i].shape)\n",
    "       # print('Y', Y[i].shape)\n",
    "        \n",
    "        X_shuffled = X_and_Y[:,:-1]\n",
    "        Y_shuffled = X_and_Y[:,-1]\n",
    "        \n",
    "        pivot = int(X[i].shape[0]*(1-prop_test))\n",
    "        X_train.append(X_shuffled[:pivot]) \n",
    "        Y_train.append(Y_shuffled[:pivot])             \n",
    "        X_test.append(X_shuffled[pivot:]) \n",
    "        Y_test.append(Y_shuffled[pivot:])\n",
    "        \n",
    "       # print('X_train', X_train[i].shape)\n",
    "       # print('Y_train', Y_train[i].shape)\n",
    "        \n",
    "       # print('X_test', X_test[i].shape)\n",
    "       # print('Y_test', Y_test[i].shape)\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns       \n",
    "import numbers\n",
    "import copy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "cv_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_validation_curve(grid, param_to_vary,\n",
    "                                      title='Validation Curve', ylim=None,\n",
    "                                      xlim=None, log=None):\n",
    "    \"\"\"Plots train and cross-validation scores from a GridSearchCV instance's\n",
    "    best params while varying one of those params.\"\"\"\n",
    "\n",
    "    df_cv_results = pd.DataFrame(grid.cv_results_)\n",
    "    train_scores_mean = df_cv_results['mean_train_score']\n",
    "    valid_scores_mean = df_cv_results['mean_test_score']\n",
    "    train_scores_std = df_cv_results['std_train_score']\n",
    "    valid_scores_std = df_cv_results['std_test_score']\n",
    "\n",
    "    param_cols = [c for c in df_cv_results.columns if c[:6] == 'param_']\n",
    "    param_ranges = [grid.param_grid[p[6:]] for p in param_cols]\n",
    "    param_ranges_lengths = [len(pr) for pr in param_ranges]\n",
    "\n",
    "    train_scores_mean = np.array(train_scores_mean).reshape(*param_ranges_lengths)\n",
    "    valid_scores_mean = np.array(valid_scores_mean).reshape(*param_ranges_lengths)\n",
    "    train_scores_std = np.array(train_scores_std).reshape(*param_ranges_lengths)\n",
    "    valid_scores_std = np.array(valid_scores_std).reshape(*param_ranges_lengths)\n",
    "\n",
    "    param_to_vary_idx = param_cols.index('param_{}'.format(param_to_vary))\n",
    "\n",
    "    slices = []\n",
    "    for idx, param in enumerate(grid.best_params_):\n",
    "        if (idx == param_to_vary_idx):\n",
    "            slices.append(slice(None))\n",
    "            continue\n",
    "        best_param_val = grid.best_params_[param]\n",
    "        idx_of_best_param = 0\n",
    "        if isinstance(param_ranges[idx], np.ndarray):\n",
    "            idx_of_best_param = param_ranges[idx].tolist().index(best_param_val)\n",
    "        else:\n",
    "            idx_of_best_param = param_ranges[idx].index(best_param_val)\n",
    "        slices.append(idx_of_best_param)\n",
    "\n",
    "    train_scores_mean = train_scores_mean[tuple(slices)]\n",
    "    valid_scores_mean = valid_scores_mean[tuple(slices)]\n",
    "    train_scores_std = train_scores_std[tuple(slices)]\n",
    "    valid_scores_std = valid_scores_std[tuple(slices)]\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_to_vary)\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    if (ylim is None):\n",
    "        plt.ylim(0.0, 1.1)\n",
    "    else:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    if (not (xlim is None)):\n",
    "        plt.xlim(*xlim)\n",
    "\n",
    "    lw = 2\n",
    "\n",
    "    plot_fn = plt.plot\n",
    "    if log:\n",
    "        plot_fn = plt.semilogx\n",
    "\n",
    "    param_range = param_ranges[param_to_vary_idx]\n",
    "    if (not isinstance(param_range[0], numbers.Number)):\n",
    "        param_range = [str(x) for x in param_range]\n",
    "    plot_fn(param_range, train_scores_mean, label='Training score', color='r',\n",
    "            lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='r', lw=lw)\n",
    "    plot_fn(param_range, valid_scores_mean, label='Cross-validation score',\n",
    "            color='b', lw=lw)\n",
    "    plt.fill_between(param_range, valid_scores_mean - valid_scores_std,\n",
    "                     valid_scores_mean + valid_scores_std, alpha=0.1,\n",
    "                     color='b', lw=lw)\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error(Y_pred, Y):\n",
    "    return np.array(y_predicted !=  Y_test[0]).astype(np.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN model\n",
    "pipe_knn = Pipeline([\n",
    "    ('sc', StandardScaler()),     \n",
    "    ('knn', KNeighborsClassifier()) \n",
    "])\n",
    "k_max = 10\n",
    "\n",
    "def get_knn_parm(n):\n",
    "    step = math.log((n / cv_num) * (cv_num-1) ,k_max)\n",
    "    return {'knn__n_neighbors': np.power(np.arange(1,k_max), step).astype(int), 'knn__p' : [1, 2,3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "pipe_svm = Pipeline([\n",
    "    ('sc', StandardScaler()),     \n",
    "    ('svm', SVC()) \n",
    "])\n",
    "k_max = 10\n",
    "\n",
    "def get_svm_parm(n):\n",
    "    return {'svm__C': [10**c for c in np.arange(-7,3, dtype=float)], 'svm__kernel' : ['linear','rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'KNN' : \n",
    "                   {'pipe' : pipe_knn, 'params' : get_knn_parm, 'grid_list':[],'test_auc':[],'train_auc':[],'val_auc':[]},\n",
    "                'SVM' : \n",
    "               {'pipe' : pipe_svm, 'params' : get_svm_parm, 'grid_list':[],'test_auc':[],'train_auc':[],'val_auc':[]}\n",
    "              }\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y, model):\n",
    "    clf = GridSearchCV(estimator=model['pipe'],           \n",
    "                  param_grid=model['params'](x.shape[0]), \n",
    "                  cv=5,\n",
    "                  return_train_score=True,n_jobs=5, pre_dispatch = '2*n_jobs',  refit=True,scoring = 'accuracy')\n",
    "\n",
    "    return clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test,y_test, model):\n",
    "    y_pred  = model.predict(x_test)\n",
    "    return accuracy_score(y_pred,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = copy.deepcopy(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "partions = [0.2,0.5,0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_results_dic(partions, datasets, classifiers):\n",
    "    results_dic = {}\n",
    "    for i, part in enumerate(partions, start=0):\n",
    "        results_dic[i] = {'partion' : part, 'datasets':{}}\n",
    "        for dataset in datasets.items():\n",
    "            results_dic[i]['datasets'][dataset[1]] = {'index' : dataset[0], 'classifiers':copy.deepcopy(classifiers)}\n",
    "    return results_dic\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_avrg_auc_over_n_trials(n, results_dic):\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        print('\\ttrial', i)\n",
    "        X_train, Y_train, X_test, Y_test = get_random_train_test(results_dic['partion'])\n",
    "        for dataset in results_dic['datasets']:\n",
    "            print('\\t\\tdataset', dataset)\n",
    "            dataset = results_dic['datasets'][dataset]\n",
    "            for classifier in dataset['classifiers']:\n",
    "                print('\\t\\t\\ttunning ', classifier)\n",
    "                classifier = dataset['classifiers'][classifier]\n",
    "                grid = train(X_train[dataset['index']],Y_train[dataset['index']], classifier)\n",
    "                classifier['test_auc'].append(test(X_test[dataset['index']], Y_test[dataset['index']],grid))\n",
    "                classifier['train_auc'].append(grid.cv_results_['mean_train_score'][grid.best_index_])\n",
    "                classifier['val_auc'].append(grid.cv_results_['mean_test_score'][grid.best_index_])\n",
    "\n",
    "                classifier['grid_list'].append(grid)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_core_loop():\n",
    "    results_dic = new_results_dic(partions, datasets, classifiers)\n",
    "    for part in results_dic.values():\n",
    "        print('partion', part['partion'])\n",
    "        update_avrg_auc_over_n_trials(3, part)\n",
    "    return results_dic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partion 0.2\n",
      "\ttrial 0\n",
      "\t\tdataset tic_tac\n",
      "\t\t\ttunning  KNN\n"
     ]
    }
   ],
   "source": [
    "results_dic = run_core_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partion 80 / 20\n",
      "\tdataset tic_tac\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.75\n",
      "\t\t\ttrain_auc 0.9307013615669215\n",
      "\t\t\tval_auc 0.7885097473332767\n",
      "\tdataset adult\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7466666666666667\n",
      "\t\t\ttrain_auc 0.7575000000000001\n",
      "\t\t\tval_auc 0.7541666666666667\n",
      "\tdataset cloud\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7466666666666667\n",
      "\t\t\ttrain_auc 0.775625\n",
      "\t\t\tval_auc 0.7683333333333334\n",
      "\tdataset my_dota\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.54\n",
      "\t\t\ttrain_auc 1.0\n",
      "\t\t\tval_auc 0.5599999999999999\n",
      "\tdataset uci_data\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.52\n",
      "\t\t\ttrain_auc 0.5758333333333333\n",
      "\t\t\tval_auc 0.555\n",
      "partion 50 / 50\n",
      "\tdataset tic_tac\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7849686847599165\n",
      "\t\t\ttrain_auc 0.8905669785320568\n",
      "\t\t\tval_auc 0.8183406432748538\n",
      "\tdataset adult\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7506666666666667\n",
      "\t\t\ttrain_auc 0.757\n",
      "\t\t\tval_auc 0.7493333333333333\n",
      "\tdataset cloud\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7506666666666667\n",
      "\t\t\ttrain_auc 0.785\n",
      "\t\t\tval_auc 0.7693333333333334\n",
      "\tdataset my_dota\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.49866666666666665\n",
      "\t\t\ttrain_auc 0.646\n",
      "\t\t\tval_auc 0.552\n",
      "\tdataset uci_data\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.4666666666666667\n",
      "\t\t\ttrain_auc 0.623\n",
      "\t\t\tval_auc 0.5720000000000001\n",
      "partion 19 / 80\n",
      "\tdataset tic_tac\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7348978704910909\n",
      "\t\t\ttrain_auc 0.8425065932805871\n",
      "\t\t\tval_auc 0.768106162843005\n",
      "\tdataset adult\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.7206982543640897\n",
      "\t\t\ttrain_auc 0.7626476793248945\n",
      "\t\t\tval_auc 0.7547368421052632\n",
      "\tdataset cloud\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.6807980049875312\n",
      "\t\t\ttrain_auc 0.8181540084388186\n",
      "\t\t\tval_auc 0.7475438596491228\n",
      "\tdataset my_dota\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.5012468827930174\n",
      "\t\t\ttrain_auc 0.6018037974683544\n",
      "\t\t\tval_auc 0.5863157894736842\n",
      "\tdataset uci_data\n",
      "\t\t KNN\n",
      "\t\t\ttest_auc 0.5020781379883624\n",
      "\t\t\ttrain_auc 0.6204219409282701\n",
      "\t\t\tval_auc 0.616140350877193\n"
     ]
    }
   ],
   "source": [
    "for part in results_dic.values():\n",
    "    print('partion', int(100*(1-part['partion'])),'/', int(100*part['partion']))\n",
    "    for dataset in part['datasets']:\n",
    "        print('\\tdataset', dataset)\n",
    "        dataset = part['datasets'][dataset]\n",
    "        for classifier in dataset['classifiers']:\n",
    "            print('\\t\\t',classifier)\n",
    "            classifier = dataset['classifiers'][classifier]\n",
    "            print('\\t\\t\\ttest_auc', mean(classifier['test_auc']))\n",
    "            print('\\t\\t\\ttrain_auc',mean(classifier['train_auc']))\n",
    "            print('\\t\\t\\tval_auc',mean(classifier['val_auc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_grid_search_validation_curve(grid, 'knn__p', log=False, ylim=(.4, 1.02))\n",
    "#plot_grid_search_validation_curve(grid, 'knn__n_neighbors', log=True, ylim=(.4, 1.02))\n",
    "#parm = classifiers['KNN']['params'](X_train[0].shape[0])\n",
    "#scores = grid.cv_results_['mean_test_score'].reshape(len(parm['knn__n_neighbors']),len(parm['knn__p']))\n",
    "#ax = sns.heatmap(scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
